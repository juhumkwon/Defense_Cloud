{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaU5mc7pmnZLNOqpkp+/UD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/Defense_Cloud/blob/main/A_12_0_1_faster_r_cnn_pre_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "75FmydEMS1dF",
        "outputId": "49c68c37-c92a-4cb5-f12f-bcf04b2b2e17"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 94)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m94\u001b[0m\n\u001b[0;31m    plt.axis('off')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 이미지 로드 (BGR → RGB 변환)\n",
        "image_path = \"/content/drive/My Drive/Data/bird.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "if image is None:\n",
        "    raise ValueError(f\"이미지를 로드할 수 없습니다: {image_path}\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 모델 입력 크기에 맞게 이미지 크기 조정\n",
        "input_size = 640\n",
        "image_resized = cv2.resize(image, (input_size, input_size))\n",
        "image_input = image_resized.astype(np.float32) / 255.0\n",
        "image_input = np.expand_dims(image_input, axis=0)  # 배치 차원 추가\n",
        "\n",
        "# TensorFlow Hub에서 Faster R-CNN 모델 로드\n",
        "# 세부 모델 구조는 URL에서 확인가능\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\")\n",
        "\n",
        "# 모델 추론 실행\n",
        "result = detector(image_input)\n",
        "result = {key: value.numpy() for key, value in result.items()}\n",
        "\n",
        "print(\"Shapes of arrays in result:\")\n",
        "for key, value in result.items():\n",
        "    if isinstance(value, np.ndarray):\n",
        "        print(f\"  {key}: {value.shape}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {type(value)}\")\n",
        "\n",
        "\n",
        "# 감지된 객체 개수 확인\n",
        "num_detections = int(result[\"num_detections\"][0])  # 감지된 객체 개수\n",
        "print(f\"Number of Detections: {num_detections}\")\n",
        "\n",
        "# 감지된 객체가 없으면 종료\n",
        "# result[\"detection_boxes\"]  # shape: (1, 100, 4)\n",
        "if num_detections == 0:\n",
        "    print(\"No objects detected.\")\n",
        "else:\n",
        "    # 결과 변수 설정\n",
        "    detection_boxes = result[\"detection_boxes\"][0][:num_detections]  # 바운딩 박스 좌표\n",
        "    detection_scores = result[\"detection_scores\"][0][:num_detections]  # 신뢰도 점수\n",
        "    detection_classes = result[\"detection_classes\"][0][:num_detections]  # 클래스 이름\n",
        "\n",
        "    # 원본 이미지 크기\n",
        "    height, width, _ = image.shape\n",
        "    score_threshold = 0.03  # 신뢰도 점수 기준 (낮춰서 더 많은 객체 검출)\n",
        "\n",
        "    # 시각화 준비\n",
        "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # 바운딩 박스 그리기\n",
        "    for i in range(num_detections):\n",
        "        score = detection_scores[i]\n",
        "        if score < score_threshold:\n",
        "            continue\n",
        "\n",
        "        ymin, xmin, ymax, xmax = detection_boxes[i]\n",
        "\n",
        "        # 정규화된 좌표를 원본 이미지 크기로 변환\n",
        "\"\"\"\n",
        "객체 탐지 모델(Faster R-CNN 등)은 보통 바운딩 박스를 0~1 사이의 비율(정규화 좌표)로 출력합니다.\n",
        "그래서 이를 실제 이미지 크기(width, height)와 곱해 픽셀 단위 좌표로 바꿔야 시각화나 후처리에 사용 가능합니다.\n",
        "\"\"\"\n",
        "        left = int(xmin * width)\n",
        "        top = int(ymin * height)\n",
        "        right = int(xmax * width)\n",
        "        bottom = int(ymax * height)\n",
        "\n",
        "        print(f\"Bounding Box {i}: ({left}, {top}) -> ({right}, {bottom}), Score: {score}\")\n",
        "\n",
        "        # 바운딩 박스 그리기\n",
        "        rect = plt.Rectangle((left, top), right - left, bottom - top, fill=False, color='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # 클래스 이름 변환 (bytes → string)\n",
        "        label = detection_classes[i]\n",
        "        if isinstance(label, bytes):\n",
        "            label = label.decode(\"ascii\")\n",
        "\n",
        "        # 바운딩 박스 위에 클래스 및 점수 표시\n",
        "        ax.text(left, top, f\"{label}: {score:.2f}\", fontsize=12, color='white',\n",
        "                bbox=dict(facecolor='red', alpha=0.5))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    }
  ]
}