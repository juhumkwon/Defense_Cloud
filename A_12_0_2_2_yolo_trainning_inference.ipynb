{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZYuo4L/2HQRG3rCSeq8+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/Defense_Cloud/blob/main/A_12_0_2_2_yolo_trainning_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "RzRK44h69-R7",
        "outputId": "5b1edd11-f001-4026-9445-dc57ec49583a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 512ms/step - loss: 65.6413\n",
            "Epoch 2/3\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 570ms/step - loss: 34.6623\n",
            "Epoch 3/3\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - loss: 33.6312\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# 1. Synthetic MNIST Detection Data\n",
        "def make_synthetic_mnist_data(num_samples=1000, image_size=128):\n",
        "    (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
        "    images, labels = [], []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        canvas = np.zeros((image_size, image_size), dtype=np.float32)\n",
        "        digit = tf.image.resize(x[i % len(x)][..., np.newaxis], (28, 28)) / 255.0\n",
        "\n",
        "        x_offset = np.random.randint(0, image_size - 28)\n",
        "        y_offset = np.random.randint(0, image_size - 28)\n",
        "        canvas[y_offset:y_offset + 28, x_offset:x_offset + 28] = digit[..., 0]\n",
        "\n",
        "        cx = (x_offset + 14) / image_size\n",
        "        cy = (y_offset + 14) / image_size\n",
        "        w = 28 / image_size\n",
        "        h = 28 / image_size\n",
        "\n",
        "        images.append(canvas[..., np.newaxis])\n",
        "        labels.append([cx, cy, w, h, y[i % len(y)]])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# 2. IoU 계산\n",
        "def compute_iou(box1, box2):\n",
        "    box1 = tf.convert_to_tensor(box1)\n",
        "    box2 = tf.convert_to_tensor(box2)\n",
        "\n",
        "    box1_xy = box1[..., :2]\n",
        "    box1_wh = box1[..., 2:4]\n",
        "    box1_min = box1_xy - box1_wh / 2\n",
        "    box1_max = box1_xy + box1_wh / 2\n",
        "\n",
        "    box2_xy = box2[..., :2]\n",
        "    box2_wh = box2[..., 2:4]\n",
        "    box2_min = box2_xy - box2_wh / 2\n",
        "    box2_max = box2_xy + box2_wh / 2\n",
        "\n",
        "    intersect_min = tf.maximum(box1_min, box2_min)\n",
        "    intersect_max = tf.minimum(box1_max, box2_max)\n",
        "    intersect_wh = tf.maximum(intersect_max - intersect_min, 0.0)\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "    area1 = box1_wh[..., 0] * box1_wh[..., 1]\n",
        "    area2 = box2_wh[..., 0] * box2_wh[..., 1]\n",
        "    union = area1 + area2 - intersect_area\n",
        "    return intersect_area / tf.maximum(union, 1e-6)\n",
        "\n",
        "# 3. YOLO 타깃 인코딩\n",
        "def encode_labels(labels, grid_size=8, anchors=[[0.2, 0.2], [0.4, 0.4], [0.6, 0.6]], num_classes=10):\n",
        "    batch_size = labels.shape[0]\n",
        "    y_true = np.zeros((batch_size, grid_size, grid_size, len(anchors), 5 + num_classes), dtype=np.float32)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        cx, cy, w, h, cls = labels[b]\n",
        "        grid_x = int(cx * grid_size)\n",
        "        grid_y = int(cy * grid_size)\n",
        "\n",
        "        best_iou = 0\n",
        "        best_anchor = 0\n",
        "        for i, anchor in enumerate(anchors):\n",
        "            iou = compute_iou([cx, cy, w, h], [cx, cy, anchor[0], anchor[1]])\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_anchor = i\n",
        "\n",
        "        tx = cx * grid_size - grid_x\n",
        "        ty = cy * grid_size - grid_y\n",
        "        tw = w / anchors[best_anchor][0]\n",
        "        th = h / anchors[best_anchor][1]\n",
        "\n",
        "        y_true[b, grid_y, grid_x, best_anchor, 0:4] = [tx, ty, tw, th]\n",
        "        y_true[b, grid_y, grid_x, best_anchor, 4] = 1.0\n",
        "        y_true[b, grid_y, grid_x, best_anchor, 5 + int(cls)] = 1.0\n",
        "\n",
        "    return y_true\n",
        "\n",
        "# 4. 모델 정의\n",
        "def yolo_anchor_model(input_shape=(128, 128, 1), grid_size=8, num_anchors=3, num_classes=10):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "    x = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(grid_size * grid_size * num_anchors * (5 + num_classes))(x)\n",
        "    x = tf.keras.layers.Reshape((grid_size, grid_size, num_anchors, 5 + num_classes))(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# 5. Loss 함수\n",
        "def yolov2_loss(y_true, y_pred):\n",
        "    obj_mask = y_true[..., 4:5]\n",
        "    noobj_mask = 1.0 - obj_mask\n",
        "\n",
        "    box_loss = tf.reduce_sum(obj_mask * tf.square(y_pred[..., 0:4] - y_true[..., 0:4]))\n",
        "    obj_loss = tf.reduce_sum(obj_mask * tf.square(y_pred[..., 4:5] - y_true[..., 4:5]))\n",
        "    noobj_loss = tf.reduce_sum(noobj_mask * tf.square(y_pred[..., 4:5]))\n",
        "    class_loss = tf.reduce_sum(obj_mask * tf.square(y_pred[..., 5:] - y_true[..., 5:]))\n",
        "    return box_loss + obj_loss + 0.5 * noobj_loss + class_loss\n",
        "\n",
        "# 6. 학습\n",
        "images, raw_labels = make_synthetic_mnist_data(1000)\n",
        "yolo_labels = encode_labels(raw_labels, grid_size=8)\n",
        "model = yolo_anchor_model()\n",
        "model.compile(optimizer='adam', loss=yolov2_loss)\n",
        "model.fit(images, yolo_labels, epochs=3, batch_size=16)\n",
        "\n",
        "# 7. 예측 결과 디코딩 및 시각화\n",
        "def decode_predictions(pred, anchors=[[0.2, 0.2], [0.4, 0.4], [0.6, 0.6]], conf_threshold=0.5):\n",
        "    pred = pred[0]  # (S, S, A, 5+C)\n",
        "    grid_size = pred.shape[0]\n",
        "    boxes = []\n",
        "\n",
        "    for y in range(grid_size):\n",
        "        for x in range(grid_size):\n",
        "            for a in range(len(anchors)):\n",
        "                tx, ty, tw, th, obj = pred[y, x, a, :5]\n",
        "                if obj < conf_threshold:\n",
        "                    continue\n",
        "                cx = (x + tx) / grid_size\n",
        "                cy = (y + ty) / grid_size\n",
        "                w = anchors[a][0] * tw\n",
        "                h = anchors[a][1] * th\n",
        "                class_id = np.argmax(pred[y, x, a, 5:])\n",
        "                boxes.append([cx, cy, w, h, obj, class_id])\n",
        "    return boxes\n",
        "\n",
        "def show_prediction(image, boxes):\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    image = np.stack([image.squeeze()] * 3, axis=-1)\n",
        "    h, w = image.shape[:2]\n",
        "    for box in boxes:\n",
        "        cx, cy, bw, bh, conf, cls = box\n",
        "        x1 = int((cx - bw / 2) * w)\n",
        "        y1 = int((cy - bh / 2) * h)\n",
        "        x2 = int((cx + bw / 2) * w)\n",
        "        y2 = int((cy + bh / 2) * h)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image, f\"{int(cls)}:{conf:.2f}\", (x1, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 8. 추론\n",
        "test_img = images[0:1]\n",
        "pred = model.predict(test_img)\n",
        "boxes = decode_predictions(pred)\n",
        "show_prediction(test_img[0], boxes)\n"
      ]
    }
  ]
}