{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCdApGPtxaKvVu8soKWfgI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/Defense_Cloud/blob/main/4_4_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx3Suhl4bssq",
        "outputId": "bd369175-9d11-43ce-e2d2-7b0589d518f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터셋 (간단한 예제용 텍스트 데이터)\n",
        "documents = [\n",
        "    \"I love programming\",  # 긍정\n",
        "    \"Python is amazing\",   # 긍정\n",
        "    \"I hate bugs\",         # 부정\n",
        "    \"Debugging is fun\",    # 긍정\n",
        "    \"I dislike errors\",    # 부정\n",
        "    \"Coding is awesome\",   # 긍정\n",
        "    \"I don't like debugging\",  # 부정\n",
        "    \"Programming is great\"  # 긍정\n",
        "]\n",
        "\n",
        "# 레이블 (1: 긍정, 0: 부정)\n",
        "labels = [1, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "# 텍스트 데이터를 벡터로 변환 (단어 카운트를 사용)\n",
        "vectorizer = CountVectorizer() # 텍스트 데이터를 숫자로 변환하는 도구인 CountVectorizer를 초기화하는 과정\n",
        "X = vectorizer.fit_transform(documents) # fit_transform() → 어휘 사전 생성 + 벡터 변환\n",
        "\n",
        "# 학습용과 테스트용 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Naive Bayes 분류기 모델 생성\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# 모델 학습\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"모델의 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# 예측 결과 출력\n",
        "# Get the indices of the test documents in the original documents list\n",
        "test_indices = X_test.toarray().sum(axis=1).nonzero()[0] # toarray() 메서드는 **희소 행렬을 밀집 배열(Dense Array)**로 변환합니다.\n",
        "\n",
        "# Use these indices to select the corresponding documents and predictions\n",
        "for i, pred in zip(test_indices, y_pred):\n",
        "    doc = documents[i]  # Get the document using its original index\n",
        "    print(f\"문서: {doc} -> 예측된 레이블: {'긍정' if pred == 1 else '부정'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrKZZTkCbtch",
        "outputId": "6529c957-d922-4027-96ac-1c02862c1687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 정확도: 100.00%\n",
            "문서: I love programming -> 예측된 레이블: 긍정\n",
            "문서: Python is amazing -> 예측된 레이블: 긍정\n",
            "문서: I hate bugs -> 예측된 레이블: 긍정\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 문서 리스트\n",
        "documents = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is amazing\",\n",
        "    \"Deep learning is a subset of machine learning\"\n",
        "]\n",
        "\n",
        "# CountVectorizer 초기화 및 변환\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# 변환된 희소 행렬 출력\n",
        "print(X)\n",
        "\n",
        "# 희소 행렬을 배열로 변환하여 출력\n",
        "print(X.toarray())\n",
        "\n",
        "# 어휘 사전 확인\n",
        "print(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekLm3nj9oDz3",
        "outputId": "bd910761-ff1c-4b63-f824-90572d1ead71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 13 stored elements and shape (3, 8)>\n",
            "  Coords\tValues\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 3)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 0)\t1\n",
            "  (2, 5)\t1\n",
            "  (2, 3)\t2\n",
            "  (2, 2)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 6)\t1\n",
            "[[0 0 0 1 1 1 0 0]\n",
            " [1 0 1 1 0 1 0 0]\n",
            " [0 1 1 2 0 1 1 1]]\n",
            "['amazing' 'deep' 'is' 'learning' 'love' 'machine' 'of' 'subset']\n"
          ]
        }
      ]
    }
  ]
}